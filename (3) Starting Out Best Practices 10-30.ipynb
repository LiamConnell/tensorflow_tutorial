{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro and *Invocaci√≥n Para Ponerse las Pilas*\n",
    "\n",
    "Now that we have learned a bit about Tensorflow and its function as a Deep Learning library, we will jump into the deep end and force ourselves to swim. The next several lessons will be explanations of fully functional tensorflow code in several applications. We will continue to explain all high level functions with low-level code, before accepting it, especially when it comes to mathematical transformations. \n",
    "\n",
    "We're jumping way ahead of our last lesson and will be hit with a lot of information right now, so I ask you to *ponerse las pilas*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick outline of all the things that we will do. Note that there is some code early on that we will eventually discard for the sake of using best practices, but which we show initially for demonstration.\n",
    "\n",
    "* Intro to a dataset object and exploring the MNIST data\n",
    "* Train a neural network classifier to recognize handwritten digits in the MNIST\n",
    "    * TF graph defined in global namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST handwritten dataset Intro\n",
    "\n",
    "This is a very common dataset that is often used as a \"hello world\" trivial introduction to Machine Learning image processing. It was created by the great Yann Lecunn years ago as a demonstration of convolution neural networks and we will use it for the same purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore data and learn about Datasets object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "# not sure why this code works the second time I run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11bec7320>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11bec72e8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11bec7390>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist # this is a Datasets object from the Datasets API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.next_batch(10)[0].shape) # 784 = 28^2\n",
    "print(mnist.train.next_batch(10)[1].shape) # one hot vector of numbers -> 0,1,2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = mnist.train.next_batch(1)\n",
    "i = d[0].reshape([28,28])\n",
    "a= d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x128d5f6d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bec7cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with a slightly messy implimentation of this simple problem. Here all the code is basically written out as global variables and we dont handle variable definitions well. If our model were more complex this code would be very messy; however, it helps us to see all the moving parts layed out on the floor the first time through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dim1 = 28\n",
    "img_dim2 = 28\n",
    "num_classes = 10\n",
    "\n",
    "n_input = img_dim1 * img_dim2\n",
    "n_hidden_1 = 10 # 1st layer number of features\n",
    "n_hidden_2 = 10 # 2nd layer number of features\n",
    "n_out = num_classes # out dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define placeholders\n",
    "X = tf.placeholder(dtype=tf.float32, shape = [None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float64, shape = [None, 10])    \n",
    "\n",
    "# define variables\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_out]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_out]))\n",
    "}\n",
    "\n",
    "# define model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)  # ReLU non-linearity stops linear functions from collapsing into a single linear function!\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "model = multilayer_perceptron(X, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss: softmax cross entropy\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(.001)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create session and initialize variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.1083\n",
      "3.5916\n",
      "3.5458\n",
      "2.94452\n",
      "2.82686\n"
     ]
    }
   ],
   "source": [
    "# iterate over training step and log the loss function over time\n",
    "losses = []\n",
    "for i in range(5000):\n",
    "    data = mnist.train.next_batch(100)\n",
    "    sess.run(train, {X: data[0], Y: data[1]})\n",
    "    if (i % 100 == 0) :\n",
    "        l = sess.run(loss, {X: data[0], Y: data[1]})\n",
    "        losses.append(l)\n",
    "        if i%1000==0:\n",
    "            print(l)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As training progresses we can see our loss function decreasing. This function is very useful for seeing how our model is doing in training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x126f3bc88>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACTo/wFI/2AAvoCddgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126eb4e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct: 51.0\n"
     ]
    }
   ],
   "source": [
    "# get results of model compared to target (Y).\n",
    "dense = tf.argmax(Y, axis=1)\n",
    "dense2 = tf.argmax(model, axis=1)\n",
    "\n",
    "target = sess.run(dense, {X: data[0], Y: data[1]})\n",
    "predict = sess.run(dense2, {X: data[0], Y: data[1]})\n",
    "result = mean(target == predict)*100\n",
    "print('Percentage correct: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Scope\n",
    "\n",
    "If we define a variable from within a function we begin to run into problems. We need variables to have unique names in our graph. This problem is resolved by using variable scopes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define placeholders first\n",
    "X = tf.placeholder(dtype=tf.float32, shape = [None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float64, shape = [None, 10])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define a function that we will reuse for each fully connected layer. \n",
    "def fully_connected_relu(input, output_dim, relu=True):\n",
    "    input_dim = input.get_shape().as_list()[1]\n",
    "    weights = tf.get_variable(\"weights\",shape=[input_dim, output_dim])\n",
    "    biases = tf.get_variable(\"biases\", shape=[output_dim])\n",
    "    out = tf.add(tf.matmul(input, weights), biases)\n",
    "    if relu:\n",
    "        out = tf.nn.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This code would fail:\n",
    "layer1 = fully_connected_relu(X, 10)\n",
    "layer2 = fully_connected_relu(layer1, 10)\n",
    "out = fully_connected_relu(layer2, 10, relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we solve the problem by calling the function from separate variable scopes:\n",
    "with tf.variable_scope(\"fconn1\"):\n",
    "    layer1 = fully_connected_relu(X, 10)\n",
    "with tf.variable_scope(\"fconn2\"):\n",
    "    layer2 = fully_connected_relu(layer1, 10)\n",
    "with tf.variable_scope(\"out\"):\n",
    "    out = fully_connected_relu(layer2, 10, relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.13592327e-01,   5.40731370e-01,  -4.53934968e-02,\n",
       "         -2.51842409e-01,  -1.62925363e-01,   2.20705271e-01,\n",
       "         -8.29263389e-01,   1.87850088e-01,  -3.79763842e-02,\n",
       "          5.99137247e-01],\n",
       "       [ -7.03424513e-02,   3.99404824e-01,  -6.16735816e-02,\n",
       "         -3.76412868e-01,   1.11092061e-01,  -9.40153003e-03,\n",
       "         -1.28008115e+00,   3.43054712e-01,  -9.45927203e-02,\n",
       "          7.81403780e-01],\n",
       "       [  1.47356912e-01,   2.49533758e-01,  -2.21233130e-01,\n",
       "         -3.02651167e-01,  -6.91851974e-03,   1.73129559e-01,\n",
       "         -8.92323017e-01,   4.12981778e-01,  -2.60015905e-01,\n",
       "          5.61587095e-01],\n",
       "       [  2.49858499e-01,   1.16952240e-01,  -2.51797765e-01,\n",
       "         -1.35159224e-01,   4.15011346e-02,   2.87272543e-01,\n",
       "         -1.14785016e+00,  -2.80248880e-01,  -2.83178389e-01,\n",
       "          8.68633270e-01],\n",
       "       [  1.52379096e-01,   1.97381273e-01,  -1.66648835e-01,\n",
       "         -4.33311105e-01,  -5.20137846e-02,   2.21486852e-01,\n",
       "         -1.02502000e+00,   3.14794362e-01,  -2.09548250e-01,\n",
       "          7.22333431e-01],\n",
       "       [  1.21965066e-01,   2.15902179e-01,  -1.43669009e-01,\n",
       "         -4.55732942e-01,  -3.58569920e-02,   1.94188982e-01,\n",
       "         -1.07904541e+00,   3.28764290e-01,  -1.85571223e-01,\n",
       "          7.50362694e-01],\n",
       "       [  1.80735186e-01,   1.38586015e-01,  -1.65130854e-01,\n",
       "         -4.67301428e-01,  -3.00019979e-04,   1.94377869e-01,\n",
       "         -1.16807425e+00,   2.47747302e-01,  -2.21429855e-01,\n",
       "          8.22189987e-01],\n",
       "       [  2.34461755e-01,   1.68181419e-01,  -2.55000442e-01,\n",
       "         -3.12319726e-01,  -7.13782534e-02,   2.71112919e-01,\n",
       "         -8.23758721e-01,   3.19340944e-01,  -2.99476057e-01,\n",
       "          5.75821757e-01],\n",
       "       [  2.32589588e-01,   1.23197019e-01,  -2.31412977e-01,\n",
       "         -3.67315859e-01,   1.66380703e-02,   1.99831441e-01,\n",
       "         -1.05113792e+00,   2.63588488e-01,  -2.90820003e-01,\n",
       "          7.15743423e-01],\n",
       "       [  1.62395820e-01,   2.10518420e-01,  -1.97190210e-01,\n",
       "         -1.58519775e-01,   4.52255607e-02,   2.15198651e-01,\n",
       "         -1.16442239e+00,  -2.11500645e-01,  -2.37282589e-01,\n",
       "          8.46179366e-01],\n",
       "       [  7.41184354e-02,   2.50950038e-01,  -1.32449865e-01,\n",
       "         -2.38319531e-01,   1.08900696e-01,   1.33590668e-01,\n",
       "         -1.35330987e+00,  -1.42535746e-01,  -1.61347866e-01,\n",
       "          9.45119083e-01],\n",
       "       [  2.11386859e-01,   2.09002465e-01,  -2.77667642e-01,\n",
       "         -2.37688288e-01,  -3.87251377e-03,   1.98449880e-01,\n",
       "         -8.10560346e-01,   3.90690923e-01,  -3.22086692e-01,\n",
       "          5.02567351e-01],\n",
       "       [  2.83374637e-01,   3.55234742e-03,  -1.79244891e-01,\n",
       "         -5.39440989e-01,  -2.89281309e-02,   2.73934096e-01,\n",
       "         -1.25850427e+00,   8.23156834e-02,  -2.52622277e-01,\n",
       "          9.59928572e-01],\n",
       "       [  2.22212806e-01,   1.35729194e-01,  -2.14745641e-01,\n",
       "         -3.93999457e-01,  -3.54471654e-02,   2.39953458e-01,\n",
       "         -1.00648713e+00,   2.63879955e-01,  -2.67714500e-01,\n",
       "          7.12900639e-01],\n",
       "       [  1.52876332e-01,   1.43014655e-01,  -1.37263715e-01,\n",
       "         -5.04171014e-01,   3.50777507e-02,   1.53140217e-01,\n",
       "         -1.27625263e+00,   2.44346052e-01,  -1.96451008e-01,\n",
       "          8.85841131e-01],\n",
       "       [  2.19188482e-01,   1.21272057e-01,  -2.02414170e-01,\n",
       "         -4.20089543e-01,  -1.16765499e-02,   2.20142379e-01,\n",
       "         -1.08487391e+00,   2.42999256e-01,  -2.59818494e-01,\n",
       "          7.65684128e-01],\n",
       "       [ -7.10886121e-02,   4.95844334e-01,  -6.51786923e-02,\n",
       "         -2.17572257e-01,  -1.41185030e-01,   2.30289638e-01,\n",
       "         -8.78134251e-01,   6.04251325e-02,  -6.77251518e-02,\n",
       "          6.48579597e-01],\n",
       "       [  6.64336681e-02,   3.29192877e-01,  -1.83820784e-01,\n",
       "         -2.93949544e-01,   1.66388452e-01,  -1.59385800e-03,\n",
       "         -1.09850287e+00,   4.91925538e-01,  -2.28742868e-01,\n",
       "          6.01173282e-01],\n",
       "       [  1.21020138e-01,   3.31217736e-01,  -2.21255898e-01,\n",
       "         -2.36010790e-01,  -1.38833046e-01,   2.76125550e-01,\n",
       "         -6.33213103e-01,   4.03610677e-01,  -2.37694353e-01,\n",
       "          4.28537697e-01],\n",
       "       [  6.84578121e-02,   3.60643566e-01,  -1.80998474e-01,\n",
       "         -3.08369994e-01,  -8.53342712e-02,   2.02954277e-01,\n",
       "         -7.45551169e-01,   5.14108658e-01,  -1.97112396e-01,\n",
       "          4.67535675e-01],\n",
       "       [  2.74319917e-01,   1.20680660e-01,  -2.77938545e-01,\n",
       "         -3.01071316e-01,  -3.32366228e-02,   2.58308768e-01,\n",
       "         -8.76902819e-01,   2.76608527e-01,  -3.32648605e-01,\n",
       "          6.06589019e-01],\n",
       "       [ -9.80545878e-02,   4.37590450e-01,  -2.04666555e-02,\n",
       "         -5.14039874e-01,  -8.10468271e-02,   1.26088500e-01,\n",
       "         -1.04627740e+00,   5.38369358e-01,  -2.69486010e-02,\n",
       "          6.89892113e-01],\n",
       "       [  2.34544963e-01,   1.80842593e-01,  -3.03224951e-01,\n",
       "         -2.04024553e-01,   6.78870678e-02,   1.47776872e-01,\n",
       "         -8.78977895e-01,   3.77977431e-01,  -3.58088046e-01,\n",
       "          5.15554965e-01],\n",
       "       [ -1.21645987e-01,   5.59972048e-01,  -5.21861017e-02,\n",
       "         -2.11297095e-01,  -1.51723132e-01,   2.09302470e-01,\n",
       "         -8.11653614e-01,   1.73479676e-01,  -4.37081456e-02,\n",
       "          5.75879097e-01],\n",
       "       [  2.52052844e-02,   3.72772276e-01,  -1.41734153e-01,\n",
       "         -3.59674215e-01,  -7.57087618e-02,   1.73460677e-01,\n",
       "         -8.42224956e-01,   5.18100858e-01,  -1.56941816e-01,\n",
       "          5.33408403e-01],\n",
       "       [  1.46482244e-01,   2.85346150e-01,  -2.37073869e-01,\n",
       "         -2.63304114e-01,  -7.47937560e-02,   2.27134243e-01,\n",
       "         -7.21226692e-01,   4.56216127e-01,  -2.64202148e-01,\n",
       "          4.56930250e-01],\n",
       "       [  1.31923169e-01,   2.11443320e-01,  -1.40073985e-01,\n",
       "         -4.58954126e-01,  -6.02464378e-02,   2.24741176e-01,\n",
       "         -1.06286252e+00,   2.82557011e-01,  -1.81261867e-01,\n",
       "          7.62838304e-01],\n",
       "       [  2.27702230e-01,   1.75919920e-01,  -2.50758648e-01,\n",
       "         -2.15903193e-01,  -1.36274695e-02,   2.40408570e-01,\n",
       "         -9.42111969e-01,   7.50817657e-02,  -3.04319084e-01,\n",
       "          6.64226711e-01],\n",
       "       [  1.12566054e-02,   5.48497200e-01,  -2.40894258e-02,\n",
       "         -3.88672709e-01,  -1.15134537e-01,   1.31019056e-01,\n",
       "         -7.75036454e-01,   4.66644585e-01,  -7.00025856e-02,\n",
       "          5.56833029e-01],\n",
       "       [  1.32884324e-01,   2.03576267e-01,  -1.38667151e-01,\n",
       "         -4.40146416e-01,  -4.74386215e-02,   2.18589574e-01,\n",
       "         -1.10575008e+00,   2.11031765e-01,  -1.83222279e-01,\n",
       "          7.97875881e-01],\n",
       "       [  7.93260187e-02,   2.59925425e-01,  -9.24491286e-02,\n",
       "         -5.23951352e-01,  -1.52340278e-01,   2.75790751e-01,\n",
       "         -9.94750738e-01,   3.32659274e-01,  -1.17934868e-01,\n",
       "          7.53610134e-01],\n",
       "       [  1.27114758e-01,   2.48736411e-01,  -1.52657703e-01,\n",
       "         -4.26353097e-01,  -1.46746039e-01,   2.90811300e-01,\n",
       "         -8.75067949e-01,   3.30542028e-01,  -1.80009931e-01,\n",
       "          6.54405236e-01],\n",
       "       [  2.81415462e-01,   8.51915479e-02,  -2.45761409e-01,\n",
       "         -3.36108565e-01,  -3.58495414e-02,   2.78752029e-01,\n",
       "         -1.01164019e+00,   9.53351557e-02,  -3.08063716e-01,\n",
       "          7.48327613e-01],\n",
       "       [ -3.45700979e-03,   3.42465639e-01,  -7.25910664e-02,\n",
       "         -4.90834177e-01,  -6.56184256e-02,   1.58835813e-01,\n",
       "         -1.05682981e+00,   4.47522283e-01,  -9.39163566e-02,\n",
       "          7.15814650e-01],\n",
       "       [ -3.43200564e-02,   3.84337723e-01,  -6.63800538e-02,\n",
       "         -4.73394662e-01,  -6.94087967e-02,   1.45564988e-01,\n",
       "         -1.01630104e+00,   4.96183932e-01,  -8.12682211e-02,\n",
       "          6.71951950e-01],\n",
       "       [ -1.06084645e-01,   4.51001704e-01,  -2.17887461e-02,\n",
       "         -5.02735853e-01,  -8.00704286e-02,   1.20573223e-01,\n",
       "         -1.02831995e+00,   5.55889606e-01,  -2.63743401e-02,\n",
       "          6.70030594e-01],\n",
       "       [  1.16476431e-01,   1.87159151e-01,  -1.22583494e-01,\n",
       "         -5.00441730e-01,   2.17125416e-02,   1.45981640e-01,\n",
       "         -1.24043489e+00,   2.90353060e-01,  -1.74212337e-01,\n",
       "          8.52349997e-01],\n",
       "       [ -2.09302902e-02,   4.28328842e-01,  -8.34214687e-02,\n",
       "         -3.52580547e-01,  -1.86470866e-01,   2.67547369e-01,\n",
       "         -8.04251909e-01,   3.06016207e-01,  -8.53986740e-02,\n",
       "          5.97558379e-01],\n",
       "       [  6.91964179e-02,   2.41330594e-01,  -8.79101455e-02,\n",
       "         -5.30577898e-01,  -4.43551838e-02,   1.79655358e-01,\n",
       "         -1.17007935e+00,   3.31799030e-01,  -1.25889584e-01,\n",
       "          8.25742066e-01],\n",
       "       [ -1.10501468e-01,   4.14126039e-01,   2.69639492e-03,\n",
       "         -5.56713164e-01,  -1.13414526e-02,   6.41220212e-02,\n",
       "         -1.22243035e+00,   5.07176876e-01,  -1.38704777e-02,\n",
       "          7.93763459e-01],\n",
       "       [  8.20327401e-02,   3.04578394e-01,  -1.79627866e-01,\n",
       "         -3.32146555e-01,   5.89266419e-04,   1.36130810e-01,\n",
       "         -9.35361862e-01,   4.62146044e-01,  -2.11449713e-01,\n",
       "          5.75836122e-01],\n",
       "       [ -1.06912345e-01,   4.42707777e-01,  -3.03593278e-03,\n",
       "         -5.44461131e-01,  -1.17000900e-01,   1.53681964e-01,\n",
       "         -1.03381968e+00,   5.31235695e-01,  -5.65639138e-03,\n",
       "          7.04458714e-01],\n",
       "       [ -1.94825441e-01,   5.71802974e-01,   3.33368778e-03,\n",
       "         -3.72288883e-01,  -5.80771714e-02,   7.61586428e-02,\n",
       "         -1.01194370e+00,   4.44654852e-01,   9.47439671e-03,\n",
       "          6.36636972e-01],\n",
       "       [  9.66190398e-02,   1.68087900e-01,  -1.01828128e-01,\n",
       "         -5.30794442e-01,   1.26895905e-01,   4.98374701e-02,\n",
       "         -1.45279264e+00,   2.70677805e-01,  -1.66121781e-01,\n",
       "          9.59170341e-01],\n",
       "       [  4.83712554e-03,   4.26759183e-01,  -1.32769376e-01,\n",
       "         -2.18366086e-01,  -1.06292978e-01,   2.17844024e-01,\n",
       "         -8.14726949e-01,   2.14980036e-01,  -1.44138858e-01,\n",
       "          5.63702464e-01],\n",
       "       [  3.63010466e-01,  -5.81705570e-03,  -3.61032963e-01,\n",
       "         -6.44406080e-02,   1.58736348e-01,   2.66107917e-01,\n",
       "         -1.18142128e+00,  -2.18277574e-01,  -3.88102442e-01,\n",
       "          8.39784026e-01],\n",
       "       [  4.36623693e-02,   3.47275734e-01,  -1.16267219e-01,\n",
       "         -4.25284505e-01,  -1.78737447e-01,   2.75677741e-01,\n",
       "         -8.00400376e-01,   4.34180766e-01,  -1.26531526e-01,\n",
       "          5.85301757e-01],\n",
       "       [  1.59061551e-02,   3.94660652e-01,  -1.27452716e-01,\n",
       "         -3.41617227e-01,  -1.34178981e-01,   2.27468818e-01,\n",
       "         -7.88365901e-01,   4.26861882e-01,  -1.36182904e-01,\n",
       "          5.38171530e-01],\n",
       "       [  5.33826202e-02,   2.13331118e-01,  -2.32003033e-02,\n",
       "         -6.63035929e-01,  -9.95999128e-02,   2.26251751e-01,\n",
       "         -1.28439248e+00,   2.57362396e-01,  -6.09232485e-02,\n",
       "          9.71284688e-01],\n",
       "       [  9.14690197e-02,   3.17087650e-01,  -1.55425519e-01,\n",
       "         -2.76310325e-01,  -1.18746109e-01,   2.69186616e-01,\n",
       "         -8.67114067e-01,   1.43519431e-01,  -1.80484653e-01,\n",
       "          6.42585397e-01],\n",
       "       [  2.13408798e-01,   1.07342228e-01,  -2.05917895e-01,\n",
       "         -4.08498824e-01,   8.74517858e-02,   1.33490801e-01,\n",
       "         -1.22518516e+00,   2.40890801e-01,  -2.74417520e-01,\n",
       "          8.14745486e-01],\n",
       "       [  6.92893416e-02,   2.38471523e-01,  -8.51865858e-02,\n",
       "         -5.05071044e-01,  -2.40062177e-02,   1.69769019e-01,\n",
       "         -1.22017956e+00,   2.46068403e-01,  -1.27052680e-01,\n",
       "          8.64610195e-01],\n",
       "       [  2.88969159e-01,   1.15126945e-01,  -2.98365235e-01,\n",
       "         -2.48671815e-01,   8.91934037e-02,   1.70447201e-01,\n",
       "         -9.91210699e-01,   2.47865424e-01,  -3.66512477e-01,\n",
       "          6.29738092e-01],\n",
       "       [  1.48532882e-01,   2.06923872e-01,  -1.98196918e-01,\n",
       "         -3.58895719e-01,   5.67963719e-02,   1.23804718e-01,\n",
       "         -1.08319354e+00,   3.57144386e-01,  -2.49329016e-01,\n",
       "          6.88013613e-01],\n",
       "       [  1.39903933e-01,   2.27661729e-01,  -1.92195982e-01,\n",
       "         -3.62648308e-01,   5.28016686e-03,   1.62903696e-01,\n",
       "         -1.00402582e+00,   3.73019159e-01,  -2.35621944e-01,\n",
       "          6.53215528e-01],\n",
       "       [  3.92379731e-01,   6.50405586e-02,  -4.03750211e-01,\n",
       "         -1.05782926e-01,   1.67611241e-03,   2.82691687e-01,\n",
       "         -7.00765491e-01,   2.07640454e-01,  -4.69748139e-01,\n",
       "          4.57631111e-01],\n",
       "       [ -1.48923844e-01,   5.53370297e-01,   3.29929590e-03,\n",
       "         -2.97068596e-01,  -1.76419109e-01,   2.25531787e-01,\n",
       "         -9.24700975e-01,   9.77142453e-02,   1.17869973e-02,\n",
       "          6.96134806e-01],\n",
       "       [  2.28501752e-01,   1.46319106e-01,  -2.49539971e-01,\n",
       "         -3.21238071e-01,   2.37512589e-02,   1.88989148e-01,\n",
       "         -9.89637256e-01,   3.02361935e-01,  -3.06006223e-01,\n",
       "          6.51753485e-01],\n",
       "       [  3.11796576e-01,   9.43151712e-02,  -3.19700807e-01,\n",
       "         -2.26311326e-01,   2.37900019e-02,   2.29360908e-01,\n",
       "         -8.92151594e-01,   2.26066038e-01,  -3.83934349e-01,\n",
       "          5.91121137e-01],\n",
       "       [  1.46965414e-01,   2.55502373e-01,  -2.35691398e-01,\n",
       "         -2.52979606e-01,   3.98776084e-02,   1.35187060e-01,\n",
       "         -9.19804394e-01,   3.90393436e-01,  -2.78550625e-01,\n",
       "          5.54000854e-01],\n",
       "       [ -2.51248419e-01,   5.92284441e-01,   7.86828399e-02,\n",
       "         -4.72509146e-01,  -9.30643752e-02,   8.77614915e-02,\n",
       "         -1.12666726e+00,   3.87892246e-01,   8.94791186e-02,\n",
       "          7.58282721e-01],\n",
       "       [  4.47632074e-01,  -7.24074244e-02,  -4.20357704e-01,\n",
       "         -9.94453132e-02,   5.17754853e-01,  -5.36439717e-02,\n",
       "         -1.49110627e+00,   3.64180207e-02,  -5.27076483e-01,\n",
       "          8.37065339e-01],\n",
       "       [  6.38372302e-02,   3.16850722e-01,  -1.46007270e-01,\n",
       "         -3.07464898e-01,  -1.80272460e-02,   1.63522527e-01,\n",
       "         -1.00967646e+00,   2.43101344e-01,  -1.78724974e-01,\n",
       "          6.76488221e-01],\n",
       "       [  6.34516776e-02,   1.99253172e-01,  -6.64814115e-02,\n",
       "         -5.77076614e-01,   6.34039640e-02,   8.93783867e-02,\n",
       "         -1.41509891e+00,   2.83437014e-01,  -1.20751262e-01,\n",
       "          9.65054393e-01],\n",
       "       [  1.86889485e-01,   1.83824226e-01,  -2.16641799e-01,\n",
       "         -3.54010522e-01,  -5.46199083e-03,   1.94768667e-01,\n",
       "         -9.84116793e-01,   3.28923821e-01,  -2.65267581e-01,\n",
       "          6.57494903e-01],\n",
       "       [  7.12627172e-02,   3.34730864e-01,  -1.87561721e-01,\n",
       "         -3.02149653e-01,  -1.98387355e-02,   1.46030486e-01,\n",
       "         -8.53054702e-01,   5.00895977e-01,  -2.12993816e-01,\n",
       "          5.12584567e-01],\n",
       "       [ -9.87307727e-02,   5.06225109e-01,  -8.00014436e-02,\n",
       "         -2.99233913e-01,  -5.45831174e-02,   1.10858828e-01,\n",
       "         -8.88144374e-01,   4.59391207e-01,  -8.19003582e-02,\n",
       "          5.42226255e-01],\n",
       "       [  3.47684890e-01,  -3.89191359e-02,  -2.99748451e-01,\n",
       "         -3.31893504e-01,   1.62860155e-01,   1.67923018e-01,\n",
       "         -1.29076970e+00,   1.02320164e-01,  -3.71071070e-01,\n",
       "          8.69572878e-01],\n",
       "       [  2.02753291e-01,   1.85541645e-01,  -2.52769679e-01,\n",
       "         -2.86890864e-01,   4.55010384e-02,   1.56442344e-01,\n",
       "         -9.62797761e-01,   3.54461223e-01,  -3.05514395e-01,\n",
       "          6.02306962e-01],\n",
       "       [  3.94453168e-01,  -3.73310447e-02,  -3.23786765e-01,\n",
       "         -3.14966381e-01,   1.07518166e-01,   2.07399428e-01,\n",
       "         -1.13783777e+00,   1.10031158e-01,  -4.13671404e-01,\n",
       "          7.77560890e-01],\n",
       "       [  2.27181271e-01,   9.91718769e-02,  -1.86890528e-01,\n",
       "         -4.63740319e-01,  -3.49733829e-02,   2.46339232e-01,\n",
       "         -1.11740410e+00,   2.04575449e-01,  -2.45574474e-01,\n",
       "          8.16930115e-01],\n",
       "       [  9.22045410e-02,   2.81663209e-01,  -1.34212345e-01,\n",
       "         -4.44236070e-01,  -1.48256466e-01,   2.72835344e-01,\n",
       "         -8.73012066e-01,   3.90793204e-01,  -1.56246290e-01,\n",
       "          6.40247226e-01],\n",
       "       [ -7.00329244e-02,   3.76958251e-01,  -1.87934935e-02,\n",
       "         -5.11720002e-01,   2.61220336e-03,   7.97555149e-02,\n",
       "         -1.24941337e+00,   3.77613783e-01,  -4.36744094e-02,\n",
       "          8.29715490e-01],\n",
       "       [ -6.16547465e-03,   3.18109155e-01,  -4.46942449e-02,\n",
       "         -5.52728295e-01,  -6.69516921e-02,   1.62427932e-01,\n",
       "         -1.15078878e+00,   4.03174043e-01,  -6.97757006e-02,\n",
       "          8.03245068e-01],\n",
       "       [  6.31618351e-02,   2.36539721e-01,  -6.02989197e-02,\n",
       "         -5.70976794e-01,  -8.84452760e-02,   2.20468044e-01,\n",
       "         -1.18955123e+00,   2.64043659e-01,  -9.60286260e-02,\n",
       "          8.81658494e-01],\n",
       "       [ -2.45979428e-03,   3.47085834e-01,  -4.04900014e-02,\n",
       "         -5.21498322e-01,  -1.86634988e-01,   2.73827702e-01,\n",
       "         -9.83594775e-01,   3.13158810e-01,  -5.24141490e-02,\n",
       "          7.56226897e-01],\n",
       "       [  1.28876761e-01,   2.24481151e-01,  -1.57201886e-01,\n",
       "         -4.30964887e-01,  -5.52548915e-02,   2.12353751e-01,\n",
       "         -1.01067460e+00,   3.43500972e-01,  -1.95920765e-01,\n",
       "          7.04541385e-01],\n",
       "       [  2.48340875e-01,   5.47116250e-02,  -1.67619333e-01,\n",
       "         -4.97543484e-01,  -4.38782126e-02,   2.75123686e-01,\n",
       "         -1.21797347e+00,   5.47231138e-02,  -2.33802348e-01,\n",
       "          9.32400942e-01],\n",
       "       [  1.15591750e-01,   2.39746734e-01,  -1.75435513e-01,\n",
       "         -3.67941052e-01,   4.07013595e-02,   1.23981357e-01,\n",
       "         -1.08041811e+00,   3.60270590e-01,  -2.20968440e-01,\n",
       "          6.90931916e-01],\n",
       "       [  8.51549506e-02,   2.80951023e-01,  -1.51598632e-01,\n",
       "         -3.99425149e-01,  -3.75269055e-02,   1.73778713e-01,\n",
       "         -9.79805470e-01,   4.13617074e-01,  -1.83699816e-01,\n",
       "          6.48536801e-01],\n",
       "       [  3.45157593e-01,   1.90672576e-02,  -2.83587158e-01,\n",
       "         -3.60745907e-01,  -3.72881591e-02,   3.00666064e-01,\n",
       "         -9.80080962e-01,   1.52054936e-01,  -3.52804780e-01,\n",
       "          7.26897597e-01],\n",
       "       [  2.07746625e-01,   1.81870878e-01,  -2.53609896e-01,\n",
       "         -5.14834672e-02,   1.39994740e-01,   1.51448190e-01,\n",
       "         -1.19798112e+00,  -2.68335938e-01,  -3.12070578e-01,\n",
       "          8.18991780e-01],\n",
       "       [  2.76928991e-01,   1.11421280e-01,  -2.66898185e-01,\n",
       "         -3.28787327e-01,  -5.63590229e-02,   2.80694008e-01,\n",
       "         -8.83559644e-01,   2.56444573e-01,  -3.20968240e-01,\n",
       "          6.32067919e-01],\n",
       "       [  3.41037512e-01,   2.16344148e-02,  -2.92651713e-01,\n",
       "         -3.36713374e-01,   1.19705051e-02,   2.55856931e-01,\n",
       "         -1.02095497e+00,   1.66463599e-01,  -3.65909696e-01,\n",
       "          7.24134088e-01],\n",
       "       [  1.28801078e-01,   2.74246961e-01,  -2.30040863e-01,\n",
       "         -2.64335006e-01,   4.12385464e-02,   1.21172249e-01,\n",
       "         -9.05746937e-01,   4.54746068e-01,  -2.69509822e-01,\n",
       "          5.29889405e-01],\n",
       "       [  1.02330744e-01,   2.73795635e-01,  -1.56184748e-01,\n",
       "         -3.62457037e-01,  -6.39373362e-02,   2.13793918e-01,\n",
       "         -9.59816396e-01,   2.91627198e-01,  -1.88969821e-01,\n",
       "          6.67873561e-01],\n",
       "       [  2.55338877e-01,   1.52402297e-01,  -2.83360720e-01,\n",
       "         -2.69244283e-01,  -2.20866203e-02,   2.37547934e-01,\n",
       "         -8.40724826e-01,   3.20390224e-01,  -3.34371150e-01,\n",
       "          5.58376789e-01],\n",
       "       [  1.83626518e-01,   1.30462006e-01,  -1.63608432e-01,\n",
       "         -4.74007010e-01,   7.65296817e-03,   1.89568341e-01,\n",
       "         -1.19204378e+00,   2.37945214e-01,  -2.21846908e-01,\n",
       "          8.38931501e-01],\n",
       "       [  1.08672068e-01,   2.13752925e-01,  -1.27920985e-01,\n",
       "         -4.76526678e-01,   1.90709978e-02,   1.45179391e-01,\n",
       "         -1.18853402e+00,   3.20489466e-01,  -1.75666422e-01,\n",
       "          8.06332827e-01],\n",
       "       [ -2.74697840e-02,   3.68589103e-01,  -7.48613626e-02,\n",
       "         -4.39689279e-01,  -2.20994651e-03,   9.66911316e-02,\n",
       "         -1.11362815e+00,   4.31226313e-01,  -9.92365479e-02,\n",
       "          7.16576338e-01],\n",
       "       [  5.56835532e-02,   2.24372447e-01,  -9.09058452e-02,\n",
       "         -3.51374090e-01,   1.74780399e-01,   4.33657765e-02,\n",
       "         -1.54916942e+00,  -8.93930197e-02,  -1.44821778e-01,\n",
       "          1.05004573e+00],\n",
       "       [  1.25859380e-01,   2.26031303e-01,  -1.49618804e-01,\n",
       "         -4.45002705e-01,  -7.31672198e-02,   2.26726741e-01,\n",
       "         -1.00304461e+00,   3.39243710e-01,  -1.86549067e-01,\n",
       "          7.10897923e-01],\n",
       "       [ -1.17973089e-01,   4.53333884e-01,   2.21164525e-02,\n",
       "         -5.59333205e-01,  -1.71302617e-01,   2.02829674e-01,\n",
       "         -1.02113843e+00,   4.45425808e-01,   2.42764354e-02,\n",
       "          7.41046727e-01],\n",
       "       [ -7.93842971e-02,   4.53553110e-01,  -8.68513584e-02,\n",
       "         -3.81518513e-01,   9.45346057e-03,   5.13709188e-02,\n",
       "         -9.89350557e-01,   6.03430510e-01,  -9.85726416e-02,\n",
       "          5.70221424e-01],\n",
       "       [ -3.42522562e-02,   4.50362116e-01,  -1.05881587e-01,\n",
       "         -3.03634167e-01,  -1.14971966e-01,   1.93942338e-01,\n",
       "         -8.13339949e-01,   3.93215954e-01,  -1.10201925e-01,\n",
       "          5.40701032e-01],\n",
       "       [  1.42902359e-01,   1.67608544e-01,  -1.03581488e-01,\n",
       "         -5.67892194e-01,  -1.30668893e-01,   2.90985197e-01,\n",
       "         -1.10639095e+00,   2.35757932e-01,  -1.44322112e-01,\n",
       "          8.57966959e-01],\n",
       "       [  9.95835215e-02,   1.73942044e-01,  -1.41333416e-01,\n",
       "         -4.29935902e-01,   2.09152669e-01,   2.68873572e-03,\n",
       "         -1.47550344e+00,   2.62060642e-01,  -1.97006837e-01,\n",
       "          9.28095043e-01],\n",
       "       [ -1.09129816e-01,   4.32893872e-01,   2.23811567e-02,\n",
       "         -4.95396793e-01,  -9.82249156e-02,   1.62286192e-01,\n",
       "         -1.17405117e+00,   2.35203892e-01,   1.11764967e-02,\n",
       "          8.47200751e-01],\n",
       "       [  2.71276146e-01,   2.57821858e-01,  -2.63761461e-01,\n",
       "         -2.49953449e-01,   2.13917196e-01,   1.06024474e-01,\n",
       "         -9.80530858e-01,   3.39734614e-01,  -3.29352140e-01,\n",
       "          5.63997090e-01],\n",
       "       [  9.49023217e-02,   2.33114749e-01,  -9.55101848e-02,\n",
       "         -5.36600709e-01,  -1.31446943e-01,   2.65964746e-01,\n",
       "         -1.04616868e+00,   3.11824679e-01,  -1.26664549e-01,\n",
       "          7.88422287e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mnist.train.next_batch(100)\n",
    "sess.run(out, {X: data[0], Y: data[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Our Model\n",
    "\n",
    "Again looking towards the inevitable complexity of our models later on, we must now think about writing well-structured code. \n",
    "\n",
    "Definining our graph as a **class object** naively is problematic because of the nature of tensors. Remember each computation is a node with new tensor defined at that point. If we defined the prediction part of the graph as a method and called it a second time when we evaluated the loss, we would create a mess of nodes. We use **decorators** to solve this problem in a pythonic way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# this is a decorator that does two things on a function: \n",
    "#    (1) makes it behave like a `@property` that is only evaluated once\n",
    "#    (2) sets the variable scope of of all variables as the name of the function\n",
    "\n",
    "def define_scope(function):\n",
    "    attribute = '_cache_' + function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(function.__name__):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_relu(input, output_dim, relu=True):\n",
    "    input_dim = input.get_shape().as_list()[1]\n",
    "    weights = tf.get_variable(\"weights\",shape=[input_dim, output_dim])\n",
    "    biases = tf.get_variable(\"biases\", shape=[output_dim])\n",
    "    out = tf.add(tf.matmul(input, weights), biases)\n",
    "    if relu:\n",
    "        out = tf.nn.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also will feed a dictionary (actually a class with attributes) of **hyperparameters** to the model's constructor. This will allow flexibility as well as using some of the useful features that the TF community has built. This code allows us to define hyperparameters and accept command line arguments to override them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a command line flag to pass name=value pairs.\n",
    "# For example using argparse:\n",
    "#import argparse\n",
    "#parser = argparse.ArgumentParser(description='Train my model.')\n",
    "#parser.add_argument('--hparams', type=str,\n",
    "#                    help='Comma separated list of \"name=value\" pairs.')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "# Set hyperparameters\n",
    "hparams = tf.contrib.training.HParams(\n",
    "    LEARNING_RATE=0.001, \n",
    "    HIDDEN_DIM1=10,\n",
    "    HIDDEN_DIM2=10\n",
    ")\n",
    "\n",
    "# Override hyperparameters values by parsing the command line\n",
    "#hparams.parse(args.hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class nn_classifier:\n",
    "    def __init__(self, input_data, target_data, hparams): \n",
    "    \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        self.in_dim, self.out_dim = self.get_inout_dim()\n",
    "        \n",
    "        self.learning_rate = hparams.LEARNING_RATE\n",
    "        self.hidden_dim1 = hparams.HIDDEN_DIM1\n",
    "        self.hidden_dim2 = hparams.HIDDEN_DIM2\n",
    "\n",
    "        self.prediction \n",
    "        self.loss \n",
    "        self.train \n",
    "        self.evaluate \n",
    "        \n",
    "    def get_inout_dim(self):\n",
    "        in_dim = self.input_data.get_shape().as_list()[1]\n",
    "        out_dim = self.target_data.get_shape().as_list()[1]\n",
    "        return in_dim, out_dim\n",
    "    \n",
    "    @define_scope\n",
    "    def prediction(self):\n",
    "        \n",
    "        with tf.variable_scope(\"fconn1\"):\n",
    "            layer1 = fully_connected_relu(self.input_data, self.hidden_dim1)\n",
    "        with tf.variable_scope(\"fconn2\"):\n",
    "            layer2 = fully_connected_relu(layer1, self.hidden_dim2)\n",
    "        with tf.variable_scope(\"out\"):\n",
    "            out = fully_connected_relu(layer2, self.out_dim, relu=False)\n",
    "        return out\n",
    "    \n",
    "    @define_scope\n",
    "    def loss(self):\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels = self.target_data, logits = self.prediction))\n",
    "        return loss\n",
    "    \n",
    "    @define_scope\n",
    "    def train(self):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        train = optimizer.minimize(self.loss)\n",
    "        return train\n",
    "    \n",
    "    @define_scope\n",
    "    def evaluate(self):\n",
    "        dense = tf.argmax(Y, axis=1)\n",
    "        dense2 = tf.argmax(self.prediction, axis=1)\n",
    "        correct = tf.equal(dense, dense2)\n",
    "        score = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the graph and initialize it in a session\n",
    "X = tf.placeholder(dtype=tf.float32, shape = [None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float64, shape = [None, 10])\n",
    "model = nn_classifier(X, Y, hparams)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy  14.77% \t\tX-Ent Loss:   2.37\n",
      "Test accuracy  27.05% \t\tX-Ent Loss:   2.19\n",
      "Test accuracy  31.94% \t\tX-Ent Loss:   1.98\n",
      "Test accuracy  46.94% \t\tX-Ent Loss:   1.75\n",
      "Test accuracy  57.17% \t\tX-Ent Loss:   1.51\n",
      "Test accuracy  64.80% \t\tX-Ent Loss:   1.25\n",
      "Test accuracy  71.58% \t\tX-Ent Loss:   1.05\n",
      "Test accuracy  75.74% \t\tX-Ent Loss:   0.92\n",
      "Test accuracy  77.72% \t\tX-Ent Loss:   0.81\n",
      "Test accuracy  79.32% \t\tX-Ent Loss:   0.74\n"
     ]
    }
   ],
   "source": [
    "# iterate through evaluations\n",
    "for i in range(10):\n",
    "    images, labels = mnist.test.images, mnist.test.labels\n",
    "    loss, evaluate = sess.run([model.loss, model.evaluate], feed_dict={X: images, Y: labels})\n",
    "    print('Test accuracy {:6.2f}% \\t\\tX-Ent Loss: {:6.2f}'.format(100 * evaluate, loss))\n",
    "    # nested iterate through training steps\n",
    "    for i in range(1000):\n",
    "        data = mnist.train.next_batch(100)\n",
    "        images, labels = data[0], data[1]\n",
    "        sess.run(model.train, {X: data[0], Y: data[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add convolutions using model inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we define two functions that represent layers of a convolutional net. We already have the fully connected layer\n",
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class conv_net_classifier(nn_classifier):\n",
    "    def __init__(self, input_data, target_data, hparams):\n",
    "        super().__init__(input_data, target_data, hparams)\n",
    "    \n",
    "    @define_scope\n",
    "    def prediction(self):\n",
    "        \n",
    "        x_image = tf.reshape(self.input_data, [-1, 28, 28, 1]) #input shape starts as [-1,28*28], now we make 2d grid and add color chanell\n",
    "        with tf.variable_scope(\"conv_maxp_1\"):\n",
    "            conv1 = conv_relu(x_image, [5, 5, 1, 32], [32]) #[-1,28,28,32] \n",
    "            max_p1 = max_pool_2x2(conv1) # [-1,14,14,32]\n",
    "        with tf.variable_scope(\"conv_maxp_2\"):\n",
    "            conv2 = conv_relu(max_p1, [5, 5, 32, 64], [64]) #[-1,14,14,64]\n",
    "            max_p2 = max_pool_2x2(conv2) # [-1,7,7,64]\n",
    "        with tf.variable_scope(\"full_con_1\"):\n",
    "            max_p2_flat = tf.reshape(max_p2, [-1, 7*7*64]) \n",
    "            fc_1 = fully_connected_relu(max_p2_flat, 1024) #[-1,1024]\n",
    "        with tf.variable_scope('out'):\n",
    "            out = fully_connected_relu(fc_1, self.out_dim, relu=False)\n",
    "        return out\n",
    "    \n",
    "    @define_scope\n",
    "    def train(self):\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        train = optimizer.minimize(self.loss)\n",
    "        return train\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hparams = tf.contrib.training.HParams(\n",
    "    LEARNING_RATE=0.001, \n",
    "    HIDDEN_DIM1=10,\n",
    "    HIDDEN_DIM2=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the graph and initialize it in a session\n",
    "X = tf.placeholder(dtype=tf.float32, shape = [None, 784])\n",
    "Y = tf.placeholder(dtype=tf.float64, shape = [None, 10])\n",
    "model = conv_net_classifier(X, Y, hparams)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy  13.55% \t\tX-Ent Loss:  59.84\n",
      "Test accuracy  40.84% \t\tX-Ent Loss: 160.82\n",
      "Test accuracy  61.52% \t\tX-Ent Loss:  23.26\n",
      "Test accuracy  77.55% \t\tX-Ent Loss:   7.72\n",
      "Test accuracy  87.46% \t\tX-Ent Loss:   3.93\n",
      "Test accuracy  90.43% \t\tX-Ent Loss:   2.45\n",
      "Test accuracy  91.41% \t\tX-Ent Loss:   2.01\n",
      "Test accuracy  90.33% \t\tX-Ent Loss:   2.06\n",
      "Test accuracy  91.53% \t\tX-Ent Loss:   1.60\n",
      "Test accuracy  91.40% \t\tX-Ent Loss:   1.59\n"
     ]
    }
   ],
   "source": [
    "# iterate through evaluations\n",
    "for i in range(10):\n",
    "    images, labels = mnist.test.images, mnist.test.labels\n",
    "    loss, evaluate = sess.run([model.loss, model.evaluate], feed_dict={X: images, Y: labels})\n",
    "    print('Test accuracy {:6.2f}% \\t\\tX-Ent Loss: {:6.2f}'.format(100 * evaluate, loss))\n",
    "    # nested iterate through training steps\n",
    "    for i in range(10):\n",
    "        data = mnist.train.next_batch(100)\n",
    "        images, labels = data[0], data[1]\n",
    "        sess.run(model.train, {X: data[0], Y: data[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way of coding in tensorflow is far superior to simply coding as we go for each model. It allows us to interchangably plug in ideas while we test their effectiveness against each other, allowing us to tune models and hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More excercises\n",
    "\n",
    "* Create a convolutional relu function in base TF\n",
    "    * Create max pool and relu functions in base TF\n",
    "    * cross entropy: tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.softmax(y)), reduction_indices=[1]))\n",
    "* Dropout layer\n",
    "* Experiment with code structure from https://blog.metaflow.fr/tensorflow-a-proposal-of-good-practices-for-files-folders-and-models-architecture-f23171501ae3\n",
    "    * Modularize class across a directory\n",
    "    * Create a generalized model class that is meant to get overwritten\n",
    "* Question: When I overwrite a method of a class, does the first graph already get built? No, but notice that there is a second set of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(10, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(10, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
